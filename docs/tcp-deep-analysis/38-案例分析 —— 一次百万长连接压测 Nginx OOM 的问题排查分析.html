<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>技术文档</title>
    <meta name="generator" content="VuePress 1.8.0">
    
    <meta name="description" content="技术文档">
    
    <link rel="preload" href="/book-docs/tcp-deep-analysis/assets/css/0.styles.0ea9dfb1.css" as="style"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/app.411d3f03.js" as="script"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/2.8125d067.js" as="script"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/38.4afa2433.js" as="script"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/10.f0096057.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/11.afe0018d.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/12.8691dd56.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/13.4570bab2.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/14.6bb5eaad.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/15.d523fd97.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/16.be91c86f.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/17.4f301f0a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/18.e0b82547.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/19.1c34c4fb.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/20.5b297df0.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/21.1e4f6afa.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/22.1fd8c44a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/23.4806d06d.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/24.64abf514.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/25.1db6ae87.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/26.79028ade.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/27.49378cc8.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/28.3f365d4e.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/29.9e4d2797.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/3.874bed90.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/30.4e5f15e1.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/31.b0e97354.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/32.5ebf2421.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/33.75327db6.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/34.6fcf5c05.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/35.2076a0c2.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/36.db825ac9.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/37.3ce92f36.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/39.e7e9657a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/4.0892ecd3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/40.c62d5047.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/41.69a88bf2.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/42.e6229e54.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/43.e36841dc.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/44.8e5155d3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/45.4c2a7d70.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/46.9ae4ac37.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/47.a075a79f.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/5.864d5a79.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/6.19b45fc3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/7.2a1330f4.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/8.8683fe45.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/9.c6213155.js">
    <link rel="stylesheet" href="/book-docs/tcp-deep-analysis/assets/css/0.styles.0ea9dfb1.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/book-docs/tcp-deep-analysis/" class="home-link router-link-active"><!----> <span class="site-name">技术文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <ul class="sidebar-links"><li><a href="/book-docs/tcp-deep-analysis/1-开篇词 —— 小册食用指南.html" class="sidebar-link">1-开篇词 —— 小册食用指南.md</a></li><li><a href="/book-docs/tcp-deep-analysis/2-TCP_IP 历史与分层模型.html" class="sidebar-link">2-TCP_IP 历史与分层模型.md</a></li><li><a href="/book-docs/tcp-deep-analysis/3-TCP 概述 —— 可靠的、面向连接的、基于字节流、全双工的协议.html" class="sidebar-link">3-TCP 概述 —— 可靠的、面向连接的、基于字节流、全双工的协议.md</a></li><li><a href="/book-docs/tcp-deep-analysis/4-来自 Google 的协议栈测试神器 —— packetdrill.html" class="sidebar-link">4-来自 Google 的协议栈测试神器 —— packetdrill.md</a></li><li><a href="/book-docs/tcp-deep-analysis/5-支撑 TCP 协议的基石 —— 剖析首部字段.html" class="sidebar-link">5-支撑 TCP 协议的基石 —— 剖析首部字段.md</a></li><li><a href="/book-docs/tcp-deep-analysis/6-数据包大小对网络的影响 —— MTU 与 MSS 的奥秘.html" class="sidebar-link">6-数据包大小对网络的影响 —— MTU 与 MSS 的奥秘.md</a></li><li><a href="/book-docs/tcp-deep-analysis/7-繁忙的贸易港口 —— 聊聊端口号.html" class="sidebar-link">7-繁忙的贸易港口 —— 聊聊端口号.md</a></li><li><a href="/book-docs/tcp-deep-analysis/8-临时端口号是如何分配的.html" class="sidebar-link">8-临时端口号是如何分配的.md</a></li><li><a href="/book-docs/tcp-deep-analysis/9-TCP 恋爱史第一步 —— 从三次握手说起.html" class="sidebar-link">9-TCP 恋爱史第一步 —— 从三次握手说起.md</a></li><li><a href="/book-docs/tcp-deep-analysis/10-聊聊 TCP 自连接那些事.html" class="sidebar-link">10-聊聊 TCP 自连接那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/11-相见时难别亦难 —— 谈谈四次挥手.html" class="sidebar-link">11-相见时难别亦难 —— 谈谈四次挥手.md</a></li><li><a href="/book-docs/tcp-deep-analysis/12-时光机 —— TCP 头部时间戳选项.html" class="sidebar-link">12-时光机 —— TCP 头部时间戳选项.md</a></li><li><a href="/book-docs/tcp-deep-analysis/13-状态机魔鬼 —— TCP 11 种状态变迁及模拟重现.html" class="sidebar-link">13-状态机魔鬼 —— TCP 11 种状态变迁及模拟重现.md</a></li><li><a href="/book-docs/tcp-deep-analysis/14-另辟蹊径看三次握手 —— 全连接队列和半连接队列与 backlog.html" class="sidebar-link">14-另辟蹊径看三次握手 —— 全连接队列和半连接队列与 backlog.md</a></li><li><a href="/book-docs/tcp-deep-analysis/15-原始但德高望重的 DDoS 攻击方式 —— SYN Flood 攻击原理.html" class="sidebar-link">15-原始但德高望重的 DDoS 攻击方式 —— SYN Flood 攻击原理.md</a></li><li><a href="/book-docs/tcp-deep-analysis/16-嫌三次握手太慢 —— 来快速打开吧.html" class="sidebar-link">16-嫌三次握手太慢 —— 来快速打开吧.md</a></li><li><a href="/book-docs/tcp-deep-analysis/17-Address already in use —— 聊聊 Socket 选项之 SO_REUSEADDR.html" class="sidebar-link">17-Address already in use —— 聊聊 Socket 选项之 SO_REUSEADDR.md</a></li><li><a href="/book-docs/tcp-deep-analysis/18-一台主机上两个进程可以同时监听同一个端口吗.html" class="sidebar-link">18-一台主机上两个进程可以同时监听同一个端口吗.md</a></li><li><a href="/book-docs/tcp-deep-analysis/19-优雅关闭连接 —— Socket 选项之 SO_LINGER.html" class="sidebar-link">19-优雅关闭连接 —— Socket 选项之 SO_LINGER.md</a></li><li><a href="/book-docs/tcp-deep-analysis/20-一个神奇的状态 —— TIME_WAIT.html" class="sidebar-link">20-一个神奇的状态 —— TIME_WAIT.md</a></li><li><a href="/book-docs/tcp-deep-analysis/21-爱搞事情的 RST 包 —— 产生场景、Connection reset 与 Broken pipe.html" class="sidebar-link">21-爱搞事情的 RST 包 —— 产生场景、Connection reset 与 Broken pipe.md</a></li><li><a href="/book-docs/tcp-deep-analysis/22-重传机制 —— 超时重传、快速重传与 SACK.html" class="sidebar-link">22-重传机制 —— 超时重传、快速重传与 SACK.md</a></li><li><a href="/book-docs/tcp-deep-analysis/23-重传间隔有讲究 —— 多久重传才合适.html" class="sidebar-link">23-重传间隔有讲究 —— 多久重传才合适.md</a></li><li><a href="/book-docs/tcp-deep-analysis/24-TCP流量控制 —— 滑动窗口.html" class="sidebar-link">24-TCP流量控制 —— 滑动窗口.md</a></li><li><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html" class="sidebar-link">25-有风度的 TCP —— 拥塞控制.md</a></li><li><a href="/book-docs/tcp-deep-analysis/26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.html" class="sidebar-link">26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/27-TCP 回包的磨叽姐 —— 延迟确认那些事.html" class="sidebar-link">27-TCP 回包的磨叽姐 —— 延迟确认那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/28-兄弟你还活着吗 —— keepalive 原理.html" class="sidebar-link">28-兄弟你还活着吗 —— keepalive 原理.md</a></li><li><a href="/book-docs/tcp-deep-analysis/29-TCP RST 攻击与如何杀掉一条 TCP 连接.html" class="sidebar-link">29-TCP RST 攻击与如何杀掉一条 TCP 连接.md</a></li><li><a href="/book-docs/tcp-deep-analysis/30-ESTABLISHED 状态的连接收到 SYN 会回复什么？.html" class="sidebar-link">30-ESTABLISHED 状态的连接收到 SYN 会回复什么？.md</a></li><li><a href="/book-docs/tcp-deep-analysis/31-定时器一览 —— 细数 TCP 的定时器们.html" class="sidebar-link">31-定时器一览 —— 细数 TCP 的定时器们.md</a></li><li><a href="/book-docs/tcp-deep-analysis/32-网络工具篇（一） —— telnet、nc、netstat.html" class="sidebar-link">32-网络工具篇（一） —— telnet、nc、netstat.md</a></li><li><a href="/book-docs/tcp-deep-analysis/33-网络工具篇（二） —— 网络包的照妖镜 tcpdump.html" class="sidebar-link">33-网络工具篇（二） —— 网络包的照妖镜 tcpdump.md</a></li><li><a href="/book-docs/tcp-deep-analysis/34-网络命令篇（三） —— 网络分析屠龙刀 wireshark.html" class="sidebar-link">34-网络命令篇（三） —— 网络分析屠龙刀 wireshark.md</a></li><li><a href="/book-docs/tcp-deep-analysis/35-案例分析 —— JDBC 批量插入真的就批量了吗.html" class="sidebar-link">35-案例分析 —— JDBC 批量插入真的就批量了吗.md</a></li><li><a href="/book-docs/tcp-deep-analysis/36-案例分析 —— TCP RST 包导致的网络血案.html" class="sidebar-link">36-案例分析 —— TCP RST 包导致的网络血案.md</a></li><li><a href="/book-docs/tcp-deep-analysis/37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.html" class="sidebar-link">37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.md</a></li><li><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html" class="active sidebar-link">38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.md</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#现象描述" class="sidebar-link">现象描述</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#排查过程分析" class="sidebar-link">排查过程分析</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#模拟-nginx-内存上涨" class="sidebar-link">模拟 Nginx 内存上涨</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#解决方案" class="sidebar-link">解决方案</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#nginx-源码分析" class="sidebar-link">Nginx 源码分析</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html#后记" class="sidebar-link">后记</a></li></ul></li><li><a href="/book-docs/tcp-deep-analysis/39-作业题和思考题解析.html" class="sidebar-link">39-作业题和思考题解析.md</a></li><li><a href="/book-docs/tcp-deep-analysis/40-网络学习一路困难，与君共勉.html" class="sidebar-link">40-网络学习一路困难，与君共勉.md</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p>在最近的一次百万长连接压测中，32C 128G 的四台 Nginx 频繁出现 OOM，出现问题时的内存监控如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43ac3da6a9" alt=""></p> <p>排查的过程记录如下。</p> <h2 id="现象描述"><a href="#现象描述" class="header-anchor">#</a> 现象描述</h2> <p>这是一个 websocket 百万长连接收发消息的压测环境，客户端 jmeter 用了上百台机器，经过四台 Nginx 到后端服务，简化后的部署结构如下图所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43ac73dc3b" alt="nginx oom"></p> <p>在维持百万连接不发数据时，一切正常，Nginx 内存稳定。在开始大量收发数据时，Nginx 内存开始以每秒上百 M 的内存增长，直到占用内存接近 128G，woker 进程开始频繁 OOM 被系统杀掉。32 个 worker 进程每个都占用接近 4G 的内存。dmesg -T 的输出如下所示。</p> <div class="language- extra-class"><pre><code>[Fri Mar 13 18:46:44 2020] Out of memory: Kill process 28258 (nginx) score 30 or sacrifice child
[Fri Mar 13 18:46:44 2020] Killed process 28258 (nginx) total-vm:1092198764kB, anon-rss:3943668kB, file-rss:736kB, shmem-rss:4kB
</code></pre></div><p>work 进程重启后，大量长连接断连，压测就没法继续增加数据量。</p> <h2 id="排查过程分析"><a href="#排查过程分析" class="header-anchor">#</a> 排查过程分析</h2> <p>拿到这个问题，首先查看了 Nginx 和客户端两端的网络连接状态，使用 <code>ss -nt</code> 命令可以在 Nginx 看到大量 ESTABLISH 状态连接的 Send-Q 堆积很大，客户端的 Recv-Q 堆积很大。Nginx 端的 ss 部分输出如下所示。</p> <div class="language- extra-class"><pre><code>State      Recv-Q Send-Q Local Address:Port     Peer Address:Port
ESTAB      0      792024 1.1.1.1:80               2.2.2.2:50664
...
</code></pre></div><p>在 jmeter 客户端抓包偶尔可以看到较多零窗口，如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43b1beead9" alt=""></p> <p>到了这里有了一些基本的方向，首先怀疑的就是 jmeter 客户端处理能力有限，有较多消息堆积在中转的 Nginx 这里。</p> <p>为了验证想法，想办法 dump 一下 nginx 的内存看看。因为在后期内存占用较高的状况下，dump 内存很容易失败，这里在内存刚开始上涨没多久的时候开始 dump。</p> <p>首先使用 pmap 查看其中任意一个 worker 进程的内存分布，这里是 4199，使用 pmap 命令的输出如下所示。</p> <div class="language- extra-class"><pre><code>pmap -x  4199 | sort -k 3 -n -r

00007f2340539000  475240  461696  461696 rw---   [ anon ]
...
</code></pre></div><p>随后使用 <code>cat /proc/4199/smaps | grep 7f2340539000</code> 查找某一段内存的起始和结束地址，如下所示。</p> <div class="language- extra-class"><pre><code>cat /proc/3492/smaps  | grep 7f2340539000

7f2340539000-7f235d553000 rw-p 00000000 00:00 0
</code></pre></div><p>随后使用 gdb 连上这个进程，dump 出这一段内存。</p> <div class="language- extra-class"><pre><code>gdb -pid 4199

dump memory memory.dump 0x7f2340539000 0x7f235d553000
</code></pre></div><p>随后使用 strings 命令查看这个 dump 文件的可读字符串内容，可以看到是大量的请求和响应内容。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43b01308a6" alt=""></p> <p>这样坚定了是因为缓存了大量的消息导致的内存上涨。随后看了一下 Nginx 的参数配置，</p> <div class="language- extra-class"><pre><code>location / {
    proxy_pass http://xxx;
    proxy_set_header    X-Forwarded-Url  &quot;$scheme://$host$request_uri&quot;;
    proxy_redirect      off;
    proxy_http_version  1.1;
    proxy_set_header    Upgrade $http_upgrade;
    proxy_set_header    Connection &quot;upgrade&quot;;
    proxy_set_header    Cookie $http_cookie;
    proxy_set_header    Host $host;
    proxy_set_header    X-Forwarded-Proto $scheme;
    proxy_set_header    X-Real-IP $remote_addr;
    proxy_set_header    X-Forwarded-For $proxy_add_x_forwarded_for;
    client_max_body_size        512M;
    client_body_buffer_size     64M;
    proxy_connect_timeout       900;
    proxy_send_timeout          900;
    proxy_read_timeout          900;
    proxy_buffer_size        64M;
    proxy_buffers            64 16M;
    proxy_busy_buffers_size        256M;
    proxy_temp_file_write_size    512M;
}
</code></pre></div><p>可以看到 proxy_buffers 这个值设置的特别大。接下来我们来模拟一下，upstream 上下游收发速度不一致对 Nginx 内存占用的影响。</p> <h2 id="模拟-nginx-内存上涨"><a href="#模拟-nginx-内存上涨" class="header-anchor">#</a> 模拟 Nginx 内存上涨</h2> <p>我这里模拟的是缓慢收包的客户端，另外一边是一个资源充沛的后端服务端，然后观察 Nginx 的内存会不会有什么变化。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43b201b9cd" alt="nginx_oom_fast_slow"></p> <p>缓慢收包客户端是用 golang 写的，用 TCP 模拟 HTTP 请求发送，代码如下所示。</p> <div class="language- extra-class"><pre><code>package main

import (
	&quot;bufio&quot;
	&quot;fmt&quot;
	&quot;net&quot;
	&quot;time&quot;
)

func main() {
	conn, _ := net.Dial(&quot;tcp&quot;, &quot;10.211.55.10:80&quot;)
	text := &quot;GET /demo.mp4 HTTP/1.1\r\nHost: ya.test.me\r\n\r\n&quot;

	fmt.Fprintf(conn, text)
	for ; ; {
		_, _ = bufio.NewReader(conn).ReadByte()
		time.Sleep(time.Second * 3)
		println(&quot;read one byte&quot;)
	}
}
</code></pre></div><p>在测试 Nginx 上开启 pidstat 监控内存变化</p> <div class="language- extra-class"><pre><code>pidstat -p pid -r 1 1000
</code></pre></div><p>运行上面的 golang 代码，Nginx worker 进程的内存变化如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43b06e0448" alt=""></p> <p>04:12:13 是 golang 程序启动的时间，可以看到在很短的时间内，Nginx 的内存占用就涨到了 464136 kB（接近 450M)，且会维持很长一段时间。</p> <p>同时值得注意的是，proxy_buffers 的设置大小是针对单个连接而言的，如果有多个连接发过来，内存占用会继续增长。下面是同时运行两个 golang 进程对 Nginx 内存影响的结果。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43e0c3aabd" alt=""></p> <p>可以看到两个慢速客户端连接上来的时候，内存已经涨到了 900 多 M。</p> <h2 id="解决方案"><a href="#解决方案" class="header-anchor">#</a> 解决方案</h2> <p>因为要支持上百万的连接，针对单个连接的资源配额要小心又小心。一个最快改动方式是把 proxy_buffering 设置为 off，如下所示。</p> <div class="language- extra-class"><pre><code>proxy_buffering off;
</code></pre></div><p>经过实测，在压测环境修改了这个值以后，以及调小了 proxy_buffer_size 的值以后，内存稳定在了 20G 左右，没有再飙升过，内存占用截图如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43e63d94ee" alt=""></p> <p>后面可以开启 proxy_buffering，调整 proxy_buffers 的大小可以在内存消耗和性能方面取得更好的平衡。</p> <p>在测试环境重复刚才的测试，结果如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43e792161f" alt=""></p> <p>可以看到这次内存值增长了 64M 左右。为什么是增长 64M 呢？来看看 proxy_buffering 的 Nginx 文档（<a href="http://nginx.org/en/docs/http/ngx_http_proxy_module.html#proxy_buffering%EF%BC%89%E3%80%82" target="_blank" rel="noopener noreferrer">nginx.org/en/docs/htt…<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p> <blockquote><p>When buffering is enabled, nginx receives a response from the proxied server as soon as possible, saving it into the buffers set by the proxy_buffer_size and proxy_buffers directives. If the whole response does not fit into memory, a part of it can be saved to a temporary file on the disk. Writing to temporary files is controlled by the proxy_max_temp_file_size and proxy_temp_file_write_size directives.</p></blockquote> <blockquote><p>When buffering is disabled, the response is passed to a client synchronously, immediately as it is received. nginx will not try to read the whole response from the proxied server. The maximum size of the data that nginx can receive from the server at a time is set by the proxy_buffer_size directive.</p></blockquote> <p>可以看到，当 proxy_buffering 处于 on 状态时，Nginx 会尽可能多的将后端服务器返回的内容接收并存储到自己的缓冲区中，这个缓冲区的最大大小是 proxy_buffer_size * proxy_buffers 的内存。</p> <p>如果后端返回的消息很大，这些内存都放不下，会被放入到磁盘文件中。临时文件由 proxy_max_temp_file_size 和 proxy_temp_file_write_size 这两个指令决定的，这里不展开。</p> <p>当 proxy_buffering 处于 off 状态时，Nginx 不会尽可能的多的从代理 server 中读数据，而是一次最多读 proxy_buffer_size 大小的数据发送给客户端。</p> <p>Nginx 的 buffering 机制设计的初衷确实是为了解决收发两端速度不一致问题的，没有 buffering 的情况下，数据会直接从后端服务转发到客户端，如果客户端的接收速度足够快，buffering 完全可以关掉。但是这个初衷在海量连接的情况下，资源的消耗需要同时考虑进来，如果有人故意伪造比较慢的客户端，可以使用很小的代价消耗服务器上很大的资源。</p> <p>其实这是一个非阻塞编程中的典型问题，接收数据不会阻塞发送数据，发送数据不会阻塞接收数据。如果 Nginx 的两端收发数据速度不对等，缓冲区设置得又过大，就会出问题了。</p> <h2 id="nginx-源码分析"><a href="#nginx-源码分析" class="header-anchor">#</a> Nginx 源码分析</h2> <p>读取后端的响应写入本地缓冲区的源码在 <code>src/event/ngx_event_pipe.c</code> 中的 ngx_event_pipe_read_upstream 方法中。这个方法最终会调用 ngx_create_temp_buf 创建内存缓冲区。创建的次数和每次缓冲区的大小由 p-&gt;bufs.num（缓冲区个数） 和 p-&gt;bufs.size（每个缓冲区的大小）决定，这两个值就是我们在配置文件中指定的 proxy_buffers 的参数值。这部分源码如下所示。</p> <div class="language- extra-class"><pre><code>static ngx_int_t
ngx_event_pipe_read_upstream(ngx_event_pipe_t *p)
{
    for ( ;; ) {

        if (p-&gt;free_raw_bufs) {
            // ...
        } else if (p-&gt;allocated &lt; p-&gt;bufs.num) { // p-&gt;allocated 目前已分配的缓冲区个数，p-&gt;bufs.num 缓冲区个数最大大小
            /* allocate a new buf if it's still allowed */
            b = ngx_create_temp_buf(p-&gt;pool, p-&gt;bufs.size); // 创建大小为 p-&gt;bufs.size 的缓冲区
            if (b == NULL) {
                return NGX_ABORT;
            }
            p-&gt;allocated++;
        } 
    }
}
</code></pre></div><p>Nginx 源码调试的界面如下所示。</p> <p><img src="https://user-gold-cdn.xitu.io/2020/3/16/170e2e43eaac8f02" alt=""></p> <h2 id="后记"><a href="#后记" class="header-anchor">#</a> 后记</h2> <p>还有过程中一些辅助的判断方法，比如通过 strace、systemtap 工具跟踪内存的分配、释放过程，这里没有展开，这些工具是分析黑盒程序的神器。</p> <p>除此之外，在这次压测过程中还发现了 worker_connections 参数设置不合理导致 Nginx 启动完就占了 14G 内存等问题，这些问题在没有海量连接的情况下是比较难发现的。</p> <p>最后，底层原理是必备技能，调参是门艺术。上面说的内容可能都是错的，看看排查思路就好。</p> <p><a href="https://juejin.im/book/6844733788681928712/section/6844733788858089479" target="_blank" rel="noopener noreferrer">Source<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/book-docs/tcp-deep-analysis/37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.html" class="prev">
        37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.md
      </a></span> <span class="next"><a href="/book-docs/tcp-deep-analysis/39-作业题和思考题解析.html">
        39-作业题和思考题解析.md
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/book-docs/tcp-deep-analysis/assets/js/app.411d3f03.js" defer></script><script src="/book-docs/tcp-deep-analysis/assets/js/2.8125d067.js" defer></script><script src="/book-docs/tcp-deep-analysis/assets/js/38.4afa2433.js" defer></script>
  </body>
</html>
