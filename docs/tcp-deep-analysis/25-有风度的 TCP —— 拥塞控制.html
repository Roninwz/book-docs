<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>技术文档</title>
    <meta name="generator" content="VuePress 1.8.0">
    
    <meta name="description" content="技术文档">
    
    <link rel="preload" href="/book-docs/tcp-deep-analysis/assets/css/0.styles.1ae38039.css" as="style"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/app.c5d1f0fa.js" as="script"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/2.8125d067.js" as="script"><link rel="preload" href="/book-docs/tcp-deep-analysis/assets/js/24.4006c26f.js" as="script"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/10.456c114f.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/11.4f919a5c.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/12.8691dd56.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/13.6eb06c9f.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/14.8ea58ce4.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/15.99b76ce3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/16.892ccdbb.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/17.46486d87.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/18.1ae83189.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/19.6788fb0a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/20.38eb4e81.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/21.dd2d7e3c.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/22.1fd8c44a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/23.7a6fd38e.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/25.acd18f3e.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/26.d393a91d.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/27.5eb2dc92.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/28.2f7d9a61.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/29.1b6a2c80.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/3.086afb7c.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/30.7b2345d3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/31.eec26697.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/32.05263bfb.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/33.0a453fe1.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/34.6fcf5c05.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/35.2076a0c2.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/36.db825ac9.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/37.3ce92f36.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/38.419ced31.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/39.e7e9657a.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/4.1e02d683.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/40.11cc02bb.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/41.e5c285f2.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/42.d1465cb7.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/43.bba7aad7.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/44.c74f481b.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/45.4c2a7d70.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/46.917e2cae.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/47.5ae9bff9.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/5.ed3e8199.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/6.19b45fc3.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/7.2a1330f4.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/8.8683fe45.js"><link rel="prefetch" href="/book-docs/tcp-deep-analysis/assets/js/9.b4387ffc.js">
    <link rel="stylesheet" href="/book-docs/tcp-deep-analysis/assets/css/0.styles.1ae38039.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/book-docs/tcp-deep-analysis/" class="home-link router-link-active"><!----> <span class="site-name">技术文档</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <!----></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><!---->  <ul class="sidebar-links"><li><a href="/book-docs/tcp-deep-analysis/1-开篇词 —— 小册食用指南.html" class="sidebar-link">1-开篇词 —— 小册食用指南.md</a></li><li><a href="/book-docs/tcp-deep-analysis/10-聊聊 TCP 自连接那些事.html" class="sidebar-link">10-聊聊 TCP 自连接那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/11-相见时难别亦难 —— 谈谈四次挥手.html" class="sidebar-link">11-相见时难别亦难 —— 谈谈四次挥手.md</a></li><li><a href="/book-docs/tcp-deep-analysis/12-时光机 —— TCP 头部时间戳选项.html" class="sidebar-link">12-时光机 —— TCP 头部时间戳选项.md</a></li><li><a href="/book-docs/tcp-deep-analysis/13-状态机魔鬼 —— TCP 11 种状态变迁及模拟重现.html" class="sidebar-link">13-状态机魔鬼 —— TCP 11 种状态变迁及模拟重现.md</a></li><li><a href="/book-docs/tcp-deep-analysis/14-另辟蹊径看三次握手 —— 全连接队列和半连接队列与 backlog.html" class="sidebar-link">14-另辟蹊径看三次握手 —— 全连接队列和半连接队列与 backlog.md</a></li><li><a href="/book-docs/tcp-deep-analysis/15-原始但德高望重的 DDoS 攻击方式 —— SYN Flood 攻击原理.html" class="sidebar-link">15-原始但德高望重的 DDoS 攻击方式 —— SYN Flood 攻击原理.md</a></li><li><a href="/book-docs/tcp-deep-analysis/16-嫌三次握手太慢 —— 来快速打开吧.html" class="sidebar-link">16-嫌三次握手太慢 —— 来快速打开吧.md</a></li><li><a href="/book-docs/tcp-deep-analysis/17-Address already in use —— 聊聊 Socket 选项之 SO_REUSEADDR.html" class="sidebar-link">17-Address already in use —— 聊聊 Socket 选项之 SO_REUSEADDR.md</a></li><li><a href="/book-docs/tcp-deep-analysis/18-一台主机上两个进程可以同时监听同一个端口吗.html" class="sidebar-link">18-一台主机上两个进程可以同时监听同一个端口吗.md</a></li><li><a href="/book-docs/tcp-deep-analysis/19-优雅关闭连接 —— Socket 选项之 SO_LINGER.html" class="sidebar-link">19-优雅关闭连接 —— Socket 选项之 SO_LINGER.md</a></li><li><a href="/book-docs/tcp-deep-analysis/2-TCP_IP 历史与分层模型.html" class="sidebar-link">2-TCP_IP 历史与分层模型.md</a></li><li><a href="/book-docs/tcp-deep-analysis/20-一个神奇的状态 —— TIME_WAIT.html" class="sidebar-link">20-一个神奇的状态 —— TIME_WAIT.md</a></li><li><a href="/book-docs/tcp-deep-analysis/21-爱搞事情的 RST 包 —— 产生场景、Connection reset 与 Broken pipe.html" class="sidebar-link">21-爱搞事情的 RST 包 —— 产生场景、Connection reset 与 Broken pipe.md</a></li><li><a href="/book-docs/tcp-deep-analysis/22-重传机制 —— 超时重传、快速重传与 SACK.html" class="sidebar-link">22-重传机制 —— 超时重传、快速重传与 SACK.md</a></li><li><a href="/book-docs/tcp-deep-analysis/23-重传间隔有讲究 —— 多久重传才合适.html" class="sidebar-link">23-重传间隔有讲究 —— 多久重传才合适.md</a></li><li><a href="/book-docs/tcp-deep-analysis/24-TCP流量控制 —— 滑动窗口.html" class="sidebar-link">24-TCP流量控制 —— 滑动窗口.md</a></li><li><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html" class="active sidebar-link">25-有风度的 TCP —— 拥塞控制.md</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#拥塞窗口-congestion-window-cwnd" class="sidebar-link">拥塞窗口（Congestion Window，cwnd）</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#拥塞处理算法一-慢启动" class="sidebar-link">拥塞处理算法一：慢启动</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#使用-packetdrill-来演示慢启动的过程" class="sidebar-link">使用 packetdrill 来演示慢启动的过程</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#慢启动阈值-slow-start-threshold-ssthresh" class="sidebar-link">慢启动阈值（Slow Start Threshold，ssthresh）</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#拥塞避免-congestion-avoidance" class="sidebar-link">拥塞避免（Congestion Avoidance）</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#算法三-快速重传-fast-retransmit" class="sidebar-link">算法三：快速重传（Fast Retransmit)</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#选择确认-selective-acknowledgment-sack" class="sidebar-link">选择确认（Selective Acknowledgment，SACK）</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#使用-packetdrill-演示快速重传" class="sidebar-link">使用 packetdrill 演示快速重传</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#算法四-快速恢复" class="sidebar-link">算法四：快速恢复</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#慢启动、快速恢复中的快慢是什么意思" class="sidebar-link">慢启动、快速恢复中的快慢是什么意思</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#演示丢包" class="sidebar-link">演示丢包</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#为什么初始化拥塞窗口-initcwnd-是-10" class="sidebar-link">为什么初始化拥塞窗口 initcwnd 是 10</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#小结" class="sidebar-link">小结</a></li><li class="sidebar-sub-header"><a href="/book-docs/tcp-deep-analysis/25-有风度的 TCP —— 拥塞控制.html#做一道练习题" class="sidebar-link">做一道练习题</a></li></ul></li><li><a href="/book-docs/tcp-deep-analysis/26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.html" class="sidebar-link">26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/27-TCP 回包的磨叽姐 —— 延迟确认那些事.html" class="sidebar-link">27-TCP 回包的磨叽姐 —— 延迟确认那些事.md</a></li><li><a href="/book-docs/tcp-deep-analysis/28-兄弟你还活着吗 —— keepalive 原理.html" class="sidebar-link">28-兄弟你还活着吗 —— keepalive 原理.md</a></li><li><a href="/book-docs/tcp-deep-analysis/29-TCP RST 攻击与如何杀掉一条 TCP 连接.html" class="sidebar-link">29-TCP RST 攻击与如何杀掉一条 TCP 连接.md</a></li><li><a href="/book-docs/tcp-deep-analysis/3-TCP 概述 —— 可靠的、面向连接的、基于字节流、全双工的协议.html" class="sidebar-link">3-TCP 概述 —— 可靠的、面向连接的、基于字节流、全双工的协议.md</a></li><li><a href="/book-docs/tcp-deep-analysis/30-ESTABLISHED 状态的连接收到 SYN 会回复什么？.html" class="sidebar-link">30-ESTABLISHED 状态的连接收到 SYN 会回复什么？.md</a></li><li><a href="/book-docs/tcp-deep-analysis/31-定时器一览 —— 细数 TCP 的定时器们.html" class="sidebar-link">31-定时器一览 —— 细数 TCP 的定时器们.md</a></li><li><a href="/book-docs/tcp-deep-analysis/32-网络工具篇（一） —— telnet、nc、netstat.html" class="sidebar-link">32-网络工具篇（一） —— telnet、nc、netstat.md</a></li><li><a href="/book-docs/tcp-deep-analysis/33-网络工具篇（二） —— 网络包的照妖镜 tcpdump.html" class="sidebar-link">33-网络工具篇（二） —— 网络包的照妖镜 tcpdump.md</a></li><li><a href="/book-docs/tcp-deep-analysis/34-网络命令篇（三） —— 网络分析屠龙刀 wireshark.html" class="sidebar-link">34-网络命令篇（三） —— 网络分析屠龙刀 wireshark.md</a></li><li><a href="/book-docs/tcp-deep-analysis/35-案例分析 —— JDBC 批量插入真的就批量了吗.html" class="sidebar-link">35-案例分析 —— JDBC 批量插入真的就批量了吗.md</a></li><li><a href="/book-docs/tcp-deep-analysis/36-案例分析 —— TCP RST 包导致的网络血案.html" class="sidebar-link">36-案例分析 —— TCP RST 包导致的网络血案.md</a></li><li><a href="/book-docs/tcp-deep-analysis/37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.html" class="sidebar-link">37-案例分析 —— 一次 Zookeeper Connection Reset 问题排查.md</a></li><li><a href="/book-docs/tcp-deep-analysis/38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.html" class="sidebar-link">38-案例分析 —— 一次百万长连接压测 Nginx OOM 的问题排查分析.md</a></li><li><a href="/book-docs/tcp-deep-analysis/39-作业题和思考题解析.html" class="sidebar-link">39-作业题和思考题解析.md</a></li><li><a href="/book-docs/tcp-deep-analysis/4-来自 Google 的协议栈测试神器 —— packetdrill.html" class="sidebar-link">4-来自 Google 的协议栈测试神器 —— packetdrill.md</a></li><li><a href="/book-docs/tcp-deep-analysis/40-网络学习一路困难，与君共勉.html" class="sidebar-link">40-网络学习一路困难，与君共勉.md</a></li><li><a href="/book-docs/tcp-deep-analysis/5-支撑 TCP 协议的基石 —— 剖析首部字段.html" class="sidebar-link">5-支撑 TCP 协议的基石 —— 剖析首部字段.md</a></li><li><a href="/book-docs/tcp-deep-analysis/6-数据包大小对网络的影响 —— MTU 与 MSS 的奥秘.html" class="sidebar-link">6-数据包大小对网络的影响 —— MTU 与 MSS 的奥秘.md</a></li><li><a href="/book-docs/tcp-deep-analysis/7-繁忙的贸易港口 —— 聊聊端口号.html" class="sidebar-link">7-繁忙的贸易港口 —— 聊聊端口号.md</a></li><li><a href="/book-docs/tcp-deep-analysis/8-临时端口号是如何分配的.html" class="sidebar-link">8-临时端口号是如何分配的.md</a></li><li><a href="/book-docs/tcp-deep-analysis/9-TCP 恋爱史第一步 —— 从三次握手说起.html" class="sidebar-link">9-TCP 恋爱史第一步 —— 从三次握手说起.md</a></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><p>前面的文章介绍了 TCP 利用滑动窗口来做流量控制，但流量控制这种机制确实可以防止发送端向接收端过多的发送数据，但是它只关注了发送端和接收端自身的状况，而没有考虑整个网络的通信状况。于是出现了我们今天要讲的拥塞处理。</p> <p>拥塞处理主要涉及到下面这几个算法</p> <ul><li>慢启动（Slow Start）</li> <li>拥塞避免（Congestion Avoidance）</li> <li>快速重传（Fast Retransmit）和快速恢复（Fast Recovery）</li></ul> <p>为了实现上面的算法，TCP 的每条连接都有两个核心状态值：</p> <ul><li>拥塞窗口（Congestion Window，cwnd）</li> <li>慢启动阈值（Slow Start Threshold，ssthresh）</li></ul> <h2 id="拥塞窗口-congestion-window-cwnd"><a href="#拥塞窗口-congestion-window-cwnd" class="header-anchor">#</a> 拥塞窗口（Congestion Window，cwnd）</h2> <p>拥塞窗口指的是在收到对端 ACK 之前自己还能传输的最大 MSS 段数。</p> <p>它与前面介绍的接收窗口（rwnd）有什么区别呢？</p> <ul><li>接收窗口（rwnd）是<strong>接收端</strong>的限制，是接收端还能接收的数据量大小</li> <li>拥塞窗口（cwnd）是<strong>发送端</strong>的限制，是发送端在还未收到对端 ACK 之前还能发送的数据量大小</li></ul> <p>我们在 TCP 头部看到的 window 字段其实讲的接收窗口（rwnd）大小。</p> <p>拥塞窗口初始值等于操作系统的一个变量 initcwnd，最新的 linux 系统 initcwnd 默认值等于 10。</p> <p>拥塞窗口与前面介绍的发送窗口（Send Window）又有什么关系呢？</p> <p>真正的发送窗口大小 = 「接收端接收窗口大小」 与 「发送端自己拥塞窗口大小」 两者的最小值</p> <p>如果接收窗口比拥塞窗口小，表示接收端处理能力不够。如果拥塞窗口小于接收窗口，表示接收端处理能力 ok，但网络拥塞。</p> <p>这也很好理解，发送端能发送多少数据，取决于两个因素</p> <ul><li>对方能接收多少数据（接收窗口）</li> <li>自己为了避免网络拥塞主动控制不要发送过多的数据（拥塞窗口）</li></ul> <p>发送端和接收端不会交换 cwnd 这个值，这个值是维护在发送端本地内存中的一个值，发送端和接收端最大的在途字节数（未经确认的）数据包大小只能是 rwnd 和 cwnd 的最小值。</p> <p>拥塞控制的算法的本质是控制拥塞窗口（cwnd）的变化。</p> <hr> <h2 id="拥塞处理算法一-慢启动"><a href="#拥塞处理算法一-慢启动" class="header-anchor">#</a> 拥塞处理算法一：慢启动</h2> <p>在连接建立之初，应该发多少数据给接收端才是合适的呢？</p> <p>你不知道对端有多快，如果有足够的带宽，你可以选择用最快的速度传输数据，但是如果是一个缓慢的移动网络呢？如果发送的数据过多，只是造成更大的网络延迟。这是基于整个考虑，每个 TCP 连接都有一个拥塞窗口的限制，最初这个值很小，随着时间的推移，每次发送的数据量如果在不丢包的情况下，“慢慢”的递增，这种机制被称为「慢启动」</p> <p>拥塞控制是从整个网络的大局观来思考的，如果没有拥塞控制，某一时刻网络的时延增加、丢包频繁，发送端疯狂重传，会造成网络更重的负担，而更重的负担会造成更多的时延和丢包，形成雪崩的网络风暴。</p> <p>这个算法的过程如下：</p> <ul><li><p>第一步，三次握手以后，双方通过 ACK 告诉了对方自己的接收窗口（rwnd）的大小，之后就可以互相发数据了</p></li> <li><p>第二步，通信双方各自初始化自己的「拥塞窗口」（Congestion Window，cwnd）大小。</p></li> <li><p>第三步，cwnd 初始值较小时，每收到一个 ACK，cwnd + 1，每经过一个 RTT，cwnd 变为之前的两倍。 过程如下图</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a09647a07ea" alt=""></p></li></ul> <p>在初始拥塞窗口为 10 的情况下，拥塞窗口随时间的变化关系如下图</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a0965069dbd" alt=""></p> <p>因此可以得到拥塞窗口达到 N 所花费的时间公式为：</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a095a9789a3" alt=""></p> <p>假设 RTT 为 50ms，客户端和服务端的接收窗口为65535字节（64KB），初始拥塞窗口为：10段，那么要达到 64KB 的吞吐量，拥塞窗口的段数 = 65535 / 1460 = 45 段，需要的 RTT 次数 = log2（45 / 10）= 2.12 次，需要的时间 = 50 * 2.12 = 106ms。也就是客户端和服务器之间的 64KB 的吞吐量，需要 2.12 次 RTT，100ms 左右的延迟。</p> <p>早期的 Linux 的初始 cwnd 为 4，在这种情况下，需要 3.35 次 RTT，花费的实际就更长了。如果客户端和服务器之间的 RTT 很小，则这个时间基本可以忽略不计</p> <h2 id="使用-packetdrill-来演示慢启动的过程"><a href="#使用-packetdrill-来演示慢启动的过程" class="header-anchor">#</a> 使用 packetdrill 来演示慢启动的过程</h2> <p>我们用 packetdrill 脚本的方式来看慢启动的过程。模拟服务端 8080 端口往客户端传送 100000 字节的数据，客户端的 MSS 大小为1000。</p> <div class="language- extra-class"><pre><code>+0  write(4, ..., 100000) = 100000
</code></pre></div><p>packetdrill 脚本内容如下</p> <div class="language- extra-class"><pre><code>--tolerance_usecs=1000000
0 socket(..., SOCK_STREAM, IPPROTO_TCP) = 3
+0 setsockopt(3, SOL_TCP, TCP_NODELAY, [1], 4) = 0
+0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0
+0 bind(3, ..., ...) = 0
+0 listen(3, 1) = 0

+0  &lt; S 0:0(0) win 65535  &lt;mss 100&gt;
+0  &gt; S. 0:0(0) ack 1 &lt;...&gt;
+.1 &lt; . 1:1(0) ack 1 win 65535

+.1  accept(3, ..., ...) = 4

// 往客户端写 20000 字节数据
+.3  write(4, ..., 20000)  = 20000
// 预期内核会发出 10 段 MSS 数据，下面是 10 次断言
+0 &gt; . 1:101(100) ack 1 &lt;...&gt;
+0 &gt; . 101:201(100) ack 1 &lt;...&gt;
+0 &gt; . 201:301(100) ack 1 &lt;...&gt;
+0 &gt; . 301:401(100) ack 1 &lt;...&gt;
+0 &gt; . 401:501(100) ack 1 &lt;...&gt;
+0 &gt; . 501:601(100) ack 1 &lt;...&gt;
+0 &gt; . 601:701(100) ack 1 &lt;...&gt;
+0 &gt; . 701:801(100) ack 1 &lt;...&gt;
+0 &gt; . 801:901(100) ack 1 &lt;...&gt;
+0 &gt; . 901:1001(100) ack 1 &lt;...&gt;

+0 `sleep 1000000`
</code></pre></div><p><strong>第 1 步</strong>：首先通过抓包确定，是不是符合我们的预期，拥塞窗口 cwnd 为 10 ，第一次会发 10 段 MSS 的数据包，抓包结果如下。</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a095aa5c428" alt=""></p> <p>可以看到服务器一口气发了 10 段数据，然后等待客户端回复 ACK，因为我们没有写回复ACK 的代码，所以过了 300ms 以后开始重传了。</p> <p><strong>第 2 步</strong>：确认这 10 段数据 在 write 调用后面增加确认 10 个段数据的脚本。理论上拥塞窗口 cwnd 会从 10 变为 20，预期内核会发出 20 段数据</p> <div class="language- extra-class"><pre><code>+.1 &lt; . 1:1(0) ack 1001 win 65535
// 预期会发出 20 段 MSS，下面是 20 次断言
+0 &gt; . 1001:1101(100) ack 1 &lt;...&gt;
+0 &gt; . 1101:1201(100) ack 1 &lt;...&gt;
+0 &gt; . 1201:1301(100) ack 1 &lt;...&gt;
+0 &gt; . 1301:1401(100) ack 1 &lt;...&gt;
+0 &gt; . 1401:1501(100) ack 1 &lt;...&gt;
+0 &gt; . 1501:1601(100) ack 1 &lt;...&gt;
+0 &gt; . 1601:1701(100) ack 1 &lt;...&gt;
+0 &gt; . 1701:1801(100) ack 1 &lt;...&gt;
+0 &gt; . 1801:1901(100) ack 1 &lt;...&gt;
+0 &gt; . 1901:2001(100) ack 1 &lt;...&gt;
+0 &gt; . 2001:2101(100) ack 1 &lt;...&gt;
+0 &gt; . 2101:2201(100) ack 1 &lt;...&gt;
+0 &gt; . 2201:2301(100) ack 1 &lt;...&gt;
+0 &gt; . 2301:2401(100) ack 1 &lt;...&gt;
+0 &gt; . 2401:2501(100) ack 1 &lt;...&gt;
+0 &gt; . 2501:2601(100) ack 1 &lt;...&gt;
+0 &gt; . 2601:2701(100) ack 1 &lt;...&gt;
+0 &gt; . 2701:2801(100) ack 1 &lt;...&gt;
+0 &gt; . 2801:2901(100) ack 1 &lt;...&gt;
+0 &gt; . 2901:3001(100) ack 1 &lt;...&gt;
</code></pre></div><p>重新执行抓包，可以看到这次服务端发送了 20 段长度为 MSS 的数据</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a0965962377" alt=""></p> <p><strong>第 3 步</strong>：确认发送的 20 段数据 再确认发送的 20 段数据，看看内核会发送出多少数据</p> <div class="language- extra-class"><pre><code>// 确认这 20 段数据
+.2 &lt; . 1:1(0) ack 3001 win 65535

// 预期会发出 40 段 MSS 数据，下面是 40 次断言
+0 &gt; . 3001:3101(100) ack 1 &lt;...&gt;
+0 &gt; . 3101:3201(100) ack 1 &lt;...&gt;
// 中间省略若干行
+0 &gt; . 6701:6801(100) ack 1 &lt;...&gt;
+0 &gt; . 6801:6901(100) ack 1 &lt;...&gt;
+0 &gt; . 6901:7001(100) ack 1 &lt;...&gt;
</code></pre></div><p>抓包结果如下，可以看到这下服务器发送了 40 段数据</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a096c8c8c5e" alt=""></p> <p>第 4 步，确认发送的 40 段数据，理论上应该会发送 80 段数据，包序号区间：7001 ~ 15001</p> <div class="language- extra-class"><pre><code>+.2 &lt; . 1:1(0) ack 7001 win 65535
</code></pre></div><p>抓包结果如下</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a0a33f88e86" alt=""></p> <p>上面的过程通过抓包的方式来验证了慢启动指数级增大拥塞窗口 cwnd 的过程。</p> <h2 id="慢启动阈值-slow-start-threshold-ssthresh"><a href="#慢启动阈值-slow-start-threshold-ssthresh" class="header-anchor">#</a> 慢启动阈值（Slow Start Threshold，ssthresh）</h2> <p>慢启动拥塞窗口（cwnd）肯定不能无止境的指数级增长下去，否则拥塞控制就变成了「拥塞失控」了，它的阈值称为「慢启动阈值」（Slow Start Threshold，ssthresh），这是文章开头介绍的拥塞控制的第二个核心状态值。ssthresh 就是一道刹车，让拥塞窗口别涨那么快。</p> <ul><li>当 cwnd &lt; ssthresh 时，拥塞窗口按指数级增长（慢启动）</li> <li>当 cwnd &gt; ssthresh 时，拥塞窗口按线性增长（拥塞避免）</li></ul> <h2 id="拥塞避免-congestion-avoidance"><a href="#拥塞避免-congestion-avoidance" class="header-anchor">#</a> 拥塞避免（Congestion Avoidance）</h2> <p>当 cwnd &gt; ssthresh 时，拥塞窗口进入「拥塞避免」阶段，在这个阶段，每一个往返 RTT，拥塞窗口大约增加 1 个 MSS 大小，直到检测到拥塞为止。</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/12/16a1126f794fdf38" alt=""></p> <p>与慢启动的区别在于</p> <ul><li>慢启动的做法是 RTT 时间内每收到一个 ACK，拥塞窗口 cwnd 就加 1，也就是每经过 1 个 RTT，cwnd 翻倍</li> <li>拥塞避免的做法保守的多，每经过一个RTT 才将拥塞窗口加 1，不管期间收到多少个 ACK</li></ul> <p><img src="https://user-gold-cdn.xitu.io/2019/4/12/16a1126f7a2a0841" alt=""></p> <p>实际的算法是如下：，</p> <ul><li>每收到一个 ACK，将拥塞窗口增加一点点（1 / cwnd）：cwnd += 1 / cwnd</li></ul> <p>以初始 cwnd = 1 为例，cwnd 变化的过程如下图</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/12/16a1126f8a9442d0" alt=""></p> <p>所以是每经过 1 个 RTT，拥塞窗口「大约」增加 1</p> <hr> <p>前面介绍的慢启动和拥塞避免是 1988 年提出的拥塞控制方案，在 1990 年又出现了两种新的拥塞控制方案：「快速重传」和「快速恢复」</p> <h2 id="算法三-快速重传-fast-retransmit"><a href="#算法三-快速重传-fast-retransmit" class="header-anchor">#</a> 算法三：快速重传（Fast Retransmit)</h2> <p>之前重传的文章中我们介绍重传的时间间隔，要等几百毫秒才会进行第一次重传。聪明的网络协议设计者们想到了一种方法：<strong>「快速重传」</strong></p> <p>快速重传的含义是：当接收端收到一个不按序到达的数据段时，TCP 立刻发送 1 个重复 ACK，而不用等有数据捎带确认，当发送端收到 3 个或以上重复 ACK，就意识到之前发的包可能丢了，于是马上进行重传，不用傻傻的等到重传定时器超时再重传。</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/12/16a1126f8b4307c8" alt=""></p> <h2 id="选择确认-selective-acknowledgment-sack"><a href="#选择确认-selective-acknowledgment-sack" class="header-anchor">#</a> 选择确认（Selective Acknowledgment，SACK）</h2> <p>这个有一个问题，发送 3、4、5 包收到的全部是 ACK=1001，快速重传解决了一个问题: 需要重传。因为除了 2 号包，3、4、5 包也有可能丢失，那到底是只重传数据包 2 还是重传 2、3、4、5 所有包呢？</p> <p>聪明的网络协议设计者，想到了一个好办法</p> <ul><li>收到 3 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 <strong>1000</strong>（ACK=1001），[1:1001]、[2001:3001] 区间的包我也收到了</li> <li>收到 4 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 <strong>1000</strong>（ACK=1001），[1:1001]、[2001:4001] 区间的包我也收到了</li> <li>收到 5 号包的时候在 ACK 包中告诉发送端：喂，小老弟，我目前收到的最大连续的包序号是 <strong>1000</strong>（ACK=1001），[1:1001]、[2001:5001] 区间的包我也收到了</li></ul> <p>这样发送端就清楚知道只用重传 2 号数据包就可以了，数据包 3、4、5已经确认无误被对端收到。这种方式被称为 SACK（Selective Acknowledgment）。</p> <p>如下图所示：</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/12/16a1126f8b380ed9" alt=""></p> <h2 id="使用-packetdrill-演示快速重传"><a href="#使用-packetdrill-演示快速重传" class="header-anchor">#</a> 使用 packetdrill 演示快速重传</h2> <div class="language- extra-class"><pre><code>  1 --tolerance_usecs=100000
  // 常规操作：初始化
  2 0  socket(..., SOCK_STREAM, IPPROTO_TCP) = 3
  3 +0 setsockopt(3, SOL_SOCKET, SO_REUSEADDR, [1], 4) = 0
  4 +0 bind(3, ..., ...) = 0
  5 +0 listen(3, 1) = 0
  6
  7 +0  &lt; S 0:0(0) win 32792 &lt;mss 1000,sackOK,nop,nop,nop,wscale 7&gt;
  8 +0  &gt; S. 0:0(0) ack 1 &lt;...&gt;
  9 +.1 &lt; . 1:1(0) ack 1 win 257
 10
 11 +0 accept(3, ... , ...) = 4
 12 // 往客户端写 5000 字节数据
 13 +0.1 write(4, ..., 5000) = 5000
 14
 15 +.1 &lt; . 1:1(0) ack 1001 win 257 &lt;sack 1:1001,nop,nop&gt;
 // 三次重复 ack
 16 +0  &lt; . 1:1(0) ack 1001 win 257 &lt;sack 1:1001 2001:3001,nop,nop&gt;
 17 +0  &lt; . 1:1(0) ack 1001 win 257 &lt;sack 1:1001 2001:4001,nop,nop&gt;
 18 +0  &lt; . 1:1(0) ack 1001 win 257 &lt;sack 1:1001 2001:5001,nop,nop&gt;
 19 // 回复确认包，让服务端不再重试
 20 +.1 &lt; . 1:1(0) ack 5001 win 257
 21
 22 +0 `sleep 1000000`
</code></pre></div><p>用 tcpdump 抓包以供 wireshark 分析<code>sudo tcpdump -i any port 8080 -nn -A -w fast_retran.pcap</code>，使用 packetdrill 执行上面的脚本。 可以看到，完全符合我们的预期，3 次重复 ACK 以后，过了15微妙，立刻进行了重传</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/9/16a02c07dfb145ee" alt=""></p> <p>打开单个包的详情，在 ACK 包的 option 选项里，包含了 SACK 的信息，如下图：</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/9/16a02c07dfc0ce58" alt=""></p> <h2 id="算法四-快速恢复"><a href="#算法四-快速恢复" class="header-anchor">#</a> 算法四：快速恢复</h2> <p>当收到三次重复 ACK 时，进入快速恢复阶段。解释为网络轻度拥塞。</p> <ul><li>拥塞阈值 ssthresh 降低为 cwnd 的一半：ssthresh = cwnd / 2</li> <li>拥塞窗口 cwnd 设置为 ssthresh</li> <li>拥塞窗口线性增加</li></ul> <h2 id="慢启动、快速恢复中的快慢是什么意思"><a href="#慢启动、快速恢复中的快慢是什么意思" class="header-anchor">#</a> 慢启动、快速恢复中的快慢是什么意思</h2> <p>刚开始学习这部内容的时候，有一个疑惑，明明慢启动拥塞窗口是成指数级增长，那还叫慢？快速恢复拥塞窗口增长的这么慢，还叫快速恢复？</p> <p>我的理解是慢和快不是指的拥塞窗口增长的速度，而是指它们的初始值。慢启动初始值一般都很小，快速恢复的 cwnd 设置为 ssthresh</p> <h2 id="演示丢包"><a href="#演示丢包" class="header-anchor">#</a> 演示丢包</h2> <p>下面我们来演示出现丢包重传时候，拥塞窗口变化情况</p> <div class="language- extra-class"><pre><code>// 回复这 10 段数据
+.2 &lt; . 1:1(0) ack 1001 win 65535

// 预期会发出 20 段 MSS
+0 &gt; . 1001:1101(100) ack 1 &lt;...&gt;
// ... 省略若干行
+0 &gt; . 2901:3001(100) ack 1 &lt;...&gt;
</code></pre></div><p>​<br>
// 过 3 秒再回复这 20 段数据，模拟网络延迟，发送端会在这期间重传
+3 &lt; . 1:1(0) ack 3001 win 65535</p> <p>这种情况下，我们来抓包看一下</p> <p><img src="https://user-gold-cdn.xitu.io/2019/4/10/16a04a0a2807cbd2" alt=""></p> <p>本来应该发送 40 段数据的，实际上只发送了 20 段，因为 TCP 这个时候已经知道网络可能已经出现拥塞，如果发送更大量的数据，会加重拥塞。</p> <p>拥塞避免把丢包当做网络拥塞的标志，如果出现了丢包的情况，必须调整窗口的大小，避免更多的包丢失。</p> <p>拥塞避免是一个很复杂的话题，有很多种算法：TCP Reno、TCP new Reno、TCP Vegas、TCP CUBIC等，这里不做太多的展开。</p> <h2 id="为什么初始化拥塞窗口-initcwnd-是-10"><a href="#为什么初始化拥塞窗口-initcwnd-是-10" class="header-anchor">#</a> 为什么初始化拥塞窗口 initcwnd 是 10</h2> <p>最初的 TCP 初始拥塞窗口值为 3 或者 4，大于 4KB 左右，如今常见的 web 服务数据流都较短，比如一个页面只有 4k ~ 6k，在慢启动阶段，还没达到传输峰值，整个数据流就可能已经结束了。对于大文件传输，慢启动没有什么问题，慢启动造成的时延会被均摊到漫长的传输过程中。</p> <p>根据 Google 的研究，90% 的 HTTP 请求数据都在 16KB 以内，约为 10 个 TCP 段。再大比如 16，在某些地区会出现明显的丢包，因此 10 是一个比较合理的值。</p> <h2 id="小结"><a href="#小结" class="header-anchor">#</a> 小结</h2> <p>这篇文章主要以实际的案例讲解了拥塞控制的几种算法：</p> <ul><li>慢启动：拥塞窗口一开始是一个很小的值，然后每 RTT 时间翻倍</li> <li>拥塞避免：当拥塞窗口达到拥塞阈值（ssthresh）时，拥塞窗口从指数增长变为线性增长</li> <li>快速重传：发送端接收到 3 个重复 ACK 时立即进行重传</li> <li>快速恢复：当收到三次重复 ACK 时，进入快速恢复阶段，此时拥塞阈值降为之前的一半，然后进入线性增长阶段</li></ul> <h2 id="做一道练习题"><a href="#做一道练习题" class="header-anchor">#</a> 做一道练习题</h2> <p>设 TCP 的 ssthresh （慢开始门限）的初始值为 8 （单位为报文段）。当拥塞窗口上升到 12 时网络发生了超时，TCP 使用慢开始和拥塞避免。试分别求出第 1 次到第 15 次传输的各拥塞窗口大小，备注：拥塞算法使用 tahoe，初始窗口为 1。</p> <p><a href="https://juejin.im/book/6844733788681928712/section/6844733788841328647" target="_blank" rel="noopener noreferrer">Source<span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></p></div> <footer class="page-edit"><!----> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/book-docs/tcp-deep-analysis/24-TCP流量控制 —— 滑动窗口.html" class="prev">
        24-TCP流量控制 —— 滑动窗口.md
      </a></span> <span class="next"><a href="/book-docs/tcp-deep-analysis/26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.html">
        26-TCP 发包的 hold 住哥 —— Nagle 算法那些事.md
      </a>
      →
    </span></p></div> </main></div><div class="global-ui"></div></div>
    <script src="/book-docs/tcp-deep-analysis/assets/js/app.c5d1f0fa.js" defer></script><script src="/book-docs/tcp-deep-analysis/assets/js/2.8125d067.js" defer></script><script src="/book-docs/tcp-deep-analysis/assets/js/24.4006c26f.js" defer></script>
  </body>
</html>
